{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercise 13. Date and File Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### exercise 1 Date and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Current Day, Month, Year, Hour, Minute, and Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 21, Month: 1, Year: 2025\n",
      "Hour: 15, Minute: 17, Second: 28\n",
      "Timestamp: 1737452848.966817\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Extract details\n",
    "current_day = now.day\n",
    "current_month = now.month\n",
    "current_year = now.year\n",
    "current_hour = now.hour\n",
    "current_minute = now.minute\n",
    "current_second = now.second\n",
    "current_timestamp = now.timestamp()\n",
    "\n",
    "# Output\n",
    "print(f\"Day: {current_day}, Month: {current_month}, Year: {current_year}\")\n",
    "print(f\"Hour: {current_hour}, Minute: {current_minute}, Second: {current_second}\")\n",
    "print(f\"Timestamp: {current_timestamp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format the Current Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Date: 01/21/2025, 15:17:28\n"
     ]
    }
   ],
   "source": [
    "# Format the date\n",
    "formatted_date = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "# Output\n",
    "print(\"Formatted Date:\", formatted_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert String \"21 January, 2025\" to a Time Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Time: 2025-01-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Given time string\n",
    "time_string = \"21 January, 2025\"\n",
    "\n",
    "# Convert to datetime object\n",
    "converted_time = datetime.strptime(time_string, \"%d %B, %Y\")\n",
    "\n",
    "# Output\n",
    "print(\"Converted Time:\", converted_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Time Difference Between Now and New Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time until New Year: 344 days, 8:42:31.033183\n"
     ]
    }
   ],
   "source": [
    "# Define the next New Year's date\n",
    "new_year = datetime(current_year + 1, 1, 1)\n",
    "\n",
    "# Calculate the difference\n",
    "time_difference = new_year - now\n",
    "\n",
    "# Output\n",
    "print(\"Time until New Year:\", time_difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Time Difference Between 1 January 1970 and Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time since 1 January 1970: 20109 days, 15:17:28.966817\n",
      "Time in seconds: 1737472648.966817\n"
     ]
    }
   ],
   "source": [
    "# Define the epoch time (1 January 1970)\n",
    "epoch_time = datetime(1970, 1, 1)\n",
    "\n",
    "# Calculate the difference\n",
    "time_since_epoch = now - epoch_time\n",
    "\n",
    "# Output\n",
    "print(\"Time since 1 January 1970:\", time_since_epoch)\n",
    "print(\"Time in seconds:\", time_since_epoch.total_seconds())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications of the datetime Module**\n",
    "* Examples of Applications:\n",
    "* Time Series Analysis:  \n",
    "* \n",
    "1. **Analyzing trends over time** (e.g., stock prices, weather patterns).\n",
    "2. **Timestamp Activities in Applications:**\n",
    "* Logging user actions (e.g., login, logout).\n",
    "3. **Scheduling Events**:\n",
    "4. **Automating reminders**, notifications, or tasks.\n",
    "5. **Adding Posts to Blogs:**\n",
    "6. **Displaying the creation time of a blog post.**\n",
    "7. Date Manipulations:\n",
    "* Adding/subtracting days, weeks, or months to/from a given date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File handling \n",
    "Find the Ten Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama: [('the', 129), ('and', 113), ('of', 81), ('to', 70), ('our', 67), ('we', 62), ('that', 50), ('a', 48), ('is', 36), ('in', 25)]\n",
      "Michelle: [('and', 96), ('the', 85), ('to', 84), ('that', 50), ('of', 46), ('â', 42), ('a', 41), ('he', 37), ('in', 36), ('my', 28)]\n",
      "Trump: [('the', 65), ('and', 59), ('we', 43), ('will', 40), ('of', 38), ('to', 32), ('our', 30), ('is', 20), ('america', 16), ('â', 14)]\n",
      "Melania: [('and', 77), ('to', 55), ('the', 52), ('is', 29), ('i', 28), ('for', 27), ('of', 25), ('that', 24), ('a', 22), ('you', 21)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def find_most_frequent_words(text, n=10):\n",
    "    # Clean the text\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())  # Extract words and convert to lowercase\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Example usage for Obama's, Michelle's, Trump's, and Melania's speeches\n",
    "def process_speech(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return find_most_frequent_words(text)\n",
    "\n",
    "# Replace paths with the actual file paths\n",
    "obama_speech = process_speech(r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\obama_speech.txt')\n",
    "michelle_speech = process_speech(r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\michelle_obama_speech.txt')\n",
    "trump_speech = process_speech(r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\donald_speech.txt')\n",
    "melania_speech = process_speech(r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\melina_trump_speech.txt')\n",
    "\n",
    "print(\"Obama:\", obama_speech)\n",
    "print(\"Michelle:\", michelle_speech)\n",
    "print(\"Trump:\", trump_speech)\n",
    "print(\"Melania:\", melania_speech)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Similarity Between Two Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Michelle's and Melania's speeches: 0.9003770944829639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "def remove_support_words(text, stop_words_path):\n",
    "    with open(stop_words_path, 'r') as file:\n",
    "        stop_words = file.read().split()\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def check_text_similarity(text1, text2, stop_words_path):\n",
    "    text1_cleaned = clean_text(text1)\n",
    "    text2_cleaned = clean_text(text2)\n",
    "    \n",
    "    text1_filtered = remove_support_words(text1_cleaned, stop_words_path)\n",
    "    text2_filtered = remove_support_words(text2_cleaned, stop_words_path)\n",
    "    \n",
    "    vectorizer = CountVectorizer().fit_transform([text1_filtered, text2_filtered])\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0, 1]\n",
    "\n",
    "# Example usage for Michelle's and Melania's speeches\n",
    "with open(r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\michelle_obama_speech.txt', 'r') as michelle_file:\n",
    "    michelle_text = michelle_file.read()\n",
    "\n",
    "with open(r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\melina_trump_speech.txt', 'r') as melania_file:\n",
    "    melania_text = melania_file.read()\n",
    "\n",
    "similarity = check_text_similarity(michelle_text, melania_text, r'C:\\Users\\AL-ANSARY\\Documents\\Ahmad 30-Days-of-Python\\stop_words.txt')\n",
    "print(\"Similarity between Michelle's and Melania's speeches:\", similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze csv file, Count Specific Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line counts for keywords: {'python': 179, 'javascript': 184, 'java': 251}\n",
      "Lines with Java but not JavaScript: 67\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def count_lines(file_path, keywords):\n",
    "    counts = {key: 0 for key in keywords}\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            line = ' '.join(row).lower()\n",
    "            for key in keywords:\n",
    "                if key.lower() in line:\n",
    "                    counts[key] += 1\n",
    "    return counts\n",
    "\n",
    "def count_java_exclusive(file_path):\n",
    "    count = 0\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            line = ' '.join(row).lower()\n",
    "            if 'java' in line and 'javascript' not in line:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Example usage\n",
    "hacker_news_path = r'C:\\\\Users\\\\AL-ANSARY\\\\Documents\\\\Ahmad 30-Days-of-Python\\\\hacker_news.csv'\n",
    "keywords = ['python', 'javascript', 'java']\n",
    "line_counts = count_lines(hacker_news_path, keywords)\n",
    "java_exclusive_count = count_java_exclusive(hacker_news_path)\n",
    "\n",
    "print(\"Line counts for keywords:\", line_counts)\n",
    "print(\"Lines with Java but not JavaScript:\", java_exclusive_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
